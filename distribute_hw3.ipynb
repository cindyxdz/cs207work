{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Algorithms: Fibonacci\n",
    "\n",
    "Another form of recursion is tree recursion. Consider computing a fibonacci sequence, in which each number is the sum of the previous two, with the first two taken to be 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Fibonacci. \n",
    "\n",
    "\n",
    "We write Fibonacci recursively with the first two numbers as base cases.\n",
    "\n",
    "![](https://mitpress.mit.edu/sicp/full-text/book/ch1-Z-G-13.gif)\n",
    "\n",
    "(from SICP)\n",
    "\n",
    "Signature: `def fib_recursive(n)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fib_recursive(n):\n",
    "    if n == 1:\n",
    "        return 0\n",
    "    if n == 2:\n",
    "        return 1\n",
    "    return fib_recursive(n-1) + fib_recursive(n-2)\n",
    "\n",
    "for i in [1, 2, 7, 13, 29, 33]:\n",
    "    print(fib_recursive(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. \n",
    "\n",
    "What are the space and time complexities of this implementation? Hint: think aboutthe number of items in a binary tree and its depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The space complexity is $O(n)$ and the time compleity is $O(2^n)$. \n",
    "\n",
    "For space complexity, it is the depth of the binary tree n. On each level of the binary tree, we are calling the fib_recursive function, creating an additional frame that takes one unit of space. After running through the function and return a value, the frame does not exist anymore and releases the space before going to the next branch. Therefore, the maximum value of tree depth is n, which can be seen as the left most branch that goes from fib(n) to fib(1) by decrement of 1 each time in the graph above. That is, the space complexity is $O(n)$. \n",
    "\n",
    "For time complexity, it is the number of nodes that is included in the binary tree. At each node, we perform a constant number of operation, adding the value of its direct children, so the time needed at each node can be seen as constant time. To calculate the value on top of the tree, we need to tranverse through the entire tree, visiting each node exactly one time. To find the number of nodes, we notice that we break each node into two branches until we reach the bottom level. So the total number of node can be approximated by $1+2+4+\\dots+2^n = \\frac{1-2^n}{1-2} =2^n-1 = O(2^n)$. Therefore, the total time complexity is the number of nodes in the tree, which is $O(2^n)$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Programming and Iteration\n",
    "\n",
    "From Skiena\n",
    ">..**dynamic programming**, which typically removes one element from the problem, solves the smaller problem, and then uses the solution to this smaller problem to add back the element in the proper way. **Divide-and-conquer** instead splits the problem in (say) halves, solves each half, then stitches the pieces back together to form a full solution.\n",
    "\n",
    ">Dynamic programming is a technique for efficiently implementing a recursive algorithm by storing partial results. The trick is seeing whether the naive recursive algorithm computes the same subproblems over and over and over again. If so, storing the answer for each subproblems in a table to look up instead of recompute can lead to an efficient algorithm. Start with a recursive algorithm or definition. Only once we have a correct recursive algorithm do we worry about speeding it up by using a results matrix. Dynamic programming is generally the right method for optimization problems on combinatorial objects that have an inherent left to right order among components. Left-to-right objects includes: character strings, rooted trees, polygons, and integer sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.\n",
    "\n",
    "Here is an implementation of Fibonacci using dynamic programming: they key is to notice that the recurrence we used can be put into an iterative form and just stored in an ever increasing array. What is the space and time complexity here? What if you were somehow able to save the array outside of the function when u calculate `fib(M)` and subsequently had to calculate `fib(N)`, where $N>M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fib_iterative(n):\n",
    "    fibs=[]\n",
    "    fibs.append(0)\n",
    "    fibs.append(1)\n",
    "    for i in range(2, n):\n",
    "         fibs.append(fibs[i-1]+fibs[i-2])\n",
    "    return fibs[n-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "8\n",
      "144\n",
      "317811\n",
      "2178309\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 2, 7,13,29,33]:\n",
    "    print(fib_iterative(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using dynamic programing, the space complexity is $O(n)$ and the time complexity is also $O(n)$. \n",
    "\n",
    "With the iterative method, we would need an array of size $n$ to store the calculated fib values, so the space complexity is $O(n)$, which is the same as before. For time complexity, now we only need to calculate fib(n) once for all n and store all previously calculated values so that we only need constant time accessing the value. Therefore, the time complexity is reduced to $O(n)$ by using dynamic programming. \n",
    "\n",
    "If we were able to save the array outside when calculating `fib(M)`, then when we had to calculate `fib(N)` for $N>M$, we only need additional $O(N-M)$ in space and $O(N-M)$ in time. It is still linear complexity in time and space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Fibonacci with cacheing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. \n",
    "\n",
    "Use `cache` and `call_counter` as decorators on `fib_recursive` and print the fibonacci numbers for 7,13,29, 33. What order should these decorators be called to make sure `call_counter` gets the actual number of calls to `fib_recursive`?\n",
    "\n",
    "We've written the `cache` decorator for you. You have to write the `call_counter` decorator which takes the function as argument and using a `count_dictionary` whose keys are function names, counts the number of times the function is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cache(f):\n",
    "    \"\"\"a single argument function whose values may be cached\"\"\"\n",
    "    cache = {}\n",
    "    def memoized_func(x):\n",
    "        if x not in cache:\n",
    "            cache[x] = f(x)\n",
    "        return cache[x]\n",
    "    memoized_func.__name__ = f.__name__\n",
    "    return memoized_func\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def call_counter(count_dictionary):\n",
    "    def call_counter_decorator(func):\n",
    "        def inner(*args, **kwargs):\n",
    "            name = func.__name__\n",
    "            if name in count_dictionary:\n",
    "                count_dictionary[name] +=1\n",
    "            else:\n",
    "                count_dictionary[name] = 1\n",
    "            return func(*args, **kwargs)\n",
    "        return inner\n",
    "    return call_counter_decorator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 1\n",
      "2 1 2\n",
      "3 1 3\n",
      "7 8 7\n",
      "13 144 13\n",
      "29 317811 29\n",
      "33 2178309 33\n"
     ]
    }
   ],
   "source": [
    "ccounter={}\n",
    "@cache\n",
    "@call_counter(ccounter)\n",
    "def fib_recursive(n):\n",
    "    if n == 1:\n",
    "        return 0\n",
    "    if n == 2:\n",
    "        return 1\n",
    "    return fib_recursive(n-1) + fib_recursive(n-2)\n",
    "\n",
    "for i in [1,2, 3, 7,13,29, 33]:\n",
    "    print(i, fib_recursive(i), ccounter['fib_recursive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should call the `call_counter(ccounter)` first and then call the `cache()` decorator to make sure the call_counter decorator gets the actual number of calls to fib_ricursive. That is, call_counter is applied first and then we cache the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.\n",
    "\n",
    "What is the time and space complexity of the the memoized Fibonacci? HINT: assume evaluation happens left to right on sub-expressions, so that `fib_recursive(n-1)` side of the tree is evaluated first, and thus the tree is evaluated depth first, from left to right. What kind of pruning happens in the tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time complexity is $O(n)$ and the space complexity is $O(n)$ for the memoized Fibonacci. \n",
    "\n",
    "By using the memoized Fibonacci, we are basically storing all previous values as in the dynamic programming method. After traversing down the tree from left sub-expressions, we computed all `fib_recursie(n-1)`. When we then try to call `fib_recursive(n-2)`, it should have been calculated once down the left branch, and thus we only need to access the value stored before. To visualize from the tree, we basically have a long branch to the left, and having one direct child to the right but not more branches further down the tree. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.\n",
    "\n",
    "Do you really need to store the entire array in the dynamic programming implementation? Isnt it enough to have only saved the previous two Fibonacci numbers? Implement such an algorithm in `fib_iterative2(n)`. What is its space and time complexity? How is the time complexity different from that of the previous iterative attempt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "def fib_iterative2(n):\n",
    "    fibs=[0,1]\n",
    "    if n<2:\n",
    "        return fibs[n-1]\n",
    "    else:\n",
    "        for i in range(2, n):\n",
    "            fibs[0], fibs[1] = fibs[1], (fibs[0]+fibs[1])\n",
    "        return fibs[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "8\n",
      "144\n",
      "317811\n",
      "2178309\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "for i in [1, 2, 7,13,29,33]:\n",
    "    print(fib_iterative2(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need to store the entire array in dynamic programming implementation, since we would only need the previous two values when calculating the next Fibonacci number. It would be enough if we only store the previous two. This new iterative method is implemented above as `fib_recursive2(n)`. \n",
    "\n",
    "The time complexity is still $O(n)$ but the space complexity is reduced to O(1) - a constant complexity. In this case, when we want to calculate `fib(n)`, we need to calculate each of the previous Fibbonacci numbers and store the previous two in the array. With each calculation is a constant time complexity by accessing the two values and add them up, the total time complexity would be a constant time times the $n$. Therefore, the time complexity is still $O(n)$, same as in the previous iterative method. The space complexity is reduced to constant $O(1)$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6.\n",
    "\n",
    "Write an algorithm for insertion sort.\n",
    "\n",
    "![](https://camo.githubusercontent.com/8f6fedc10da579f13b22b949f6ad29255b6d721f/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f302f30662f496e73657274696f6e2d736f72742d6578616d706c652d33303070782e676966)\n",
    "\n",
    "(from wikipedia)\n",
    "\n",
    "The algorithm is also illustrated here: http://cs.armstrong.edu/liang/animation/web/InsertionSort.html and may be described thus:\n",
    "\n",
    "Insertion sort is a method for sorting that starts with a single element (thus forming a trivially sorted list) and then incrementally inserts the remaining elements so that the list stays sorted.\n",
    "\n",
    "Talk about the best, worst and average complexity of insertion sort. Use the A=[5,2,1,3,8,6,9] to show your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5, 6, 8, 9]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "def insertion_sort(input_list):\n",
    "    for i in range(1,len(input_list)):\n",
    "        j = i-1\n",
    "        while((input_list[i] < input_list[j]) & (j >= 0)):\n",
    "            input_list[i], input_list[j] = input_list[j], input_list[i]\n",
    "            j -= 1\n",
    "            i -=1\n",
    "    return input_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best complexity: The best senario for insertion sort is when the original list is already sorted. In this case, when we iterate through the list, we only need to make one comparison with the element in front. Because the list is originally sorted, we will have the current value bigger than the previous one, and thus do not need to make more comparisons or swaps. The complexity in this best case is just to iterate through the list, which is $O(n)$. \n",
    "\n",
    "Worst complexity: The worst case for insertion sort is when the original listis in reverse order. In this cae, each element would need to compare and swap with all elements in front of it. That is, for the ith element, it will swap with i-1 elements, and i ranges from 1 to n. $\\sum_{i=1}^{n} (i-1) = \\frac{(n-1)n}{2} = O(n^2)$. Therefore, the worst complexuty is $O(n^2)$. \n",
    "\n",
    "Average complexity:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_list = insertion_sort([5,2,1,3,8,6,9])\n",
    "print (sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"800\" height=\"500\" frameborder=\"0\" src=\"http://pythontutor.com/iframe-embed.html#code=def%20insertion_sort(input_list%29%3A%0A%20%20%20%20for%20i%20in%20range(1,len(input_list%29%29%3A%0A%20%20%20%20%20%20%20%20j%20%3D%20i-1%0A%20%20%20%20%20%20%20%20while((input_list%5Bi%5D%20%3C%20input_list%5Bj%5D%29%20%26%20(j%20%3E%3D%200%29%29%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20input_list%5Bi%5D,%20input_list%5Bj%5D%20%3D%20input_list%5Bj%5D,%20input_list%5Bi%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20j%20-%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20i%20-%3D1%0A%20%20%20%20return%20input_list%0Asorted_list%20%3D%20insertion_sort(%5B5,2,1,3,8,6,9%5D%29%0Aprint%20(sorted_list%29&codeDivHeight=400&codeDivWidth=350&cumulative=false&curInstr=0&heapPrimitives=false&origin=opt-frontend.js&py=3&rawInputLstJSON=%5B%5D&textReferences=false\"> </iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<iframe width=\"800\" height=\"500\" frameborder=\"0\" src=\"http://pythontutor.com/iframe-embed.html#code=def%20insertion_sort(input_list%29%3A%0A%20%20%20%20for%20i%20in%20range(1,len(input_list%29%29%3A%0A%20%20%20%20%20%20%20%20j%20%3D%20i-1%0A%20%20%20%20%20%20%20%20while((input_list%5Bi%5D%20%3C%20input_list%5Bj%5D%29%20%26%20(j%20%3E%3D%200%29%29%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20input_list%5Bi%5D,%20input_list%5Bj%5D%20%3D%20input_list%5Bj%5D,%20input_list%5Bi%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20j%20-%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20i%20-%3D1%0A%20%20%20%20return%20input_list%0Asorted_list%20%3D%20insertion_sort(%5B5,2,1,3,8,6,9%5D%29%0Aprint%20(sorted_list%29&codeDivHeight=400&codeDivWidth=350&cumulative=false&curInstr=0&heapPrimitives=false&origin=opt-frontend.js&py=3&rawInputLstJSON=%5B%5D&textReferences=false\"> </iframe>''')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
